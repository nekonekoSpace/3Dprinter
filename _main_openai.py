#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import asyncio
import json
import logging
import shutil
from typing import Optional, List, Dict, Any

from dotenv import load_dotenv
from openai import AsyncOpenAI
from agents.mcp import MCPServerStdio

load_dotenv()


def parse_args():
    p = argparse.ArgumentParser(description="FreeCAD MCP + OpenAI Áõ¥Êé•Âëº„Å≥Âá∫„ÅóREPL")
    p.add_argument("--model", default="gpt-4o", help="‰ΩøÁî®„Åô„ÇãOpenAI„É¢„Éá„É´Ôºà‰æã: gpt-4o, gpt-4o-miniÔºâ")
    p.add_argument("--doc-name", default="Main", help="‰ΩúÊ•≠„Å´‰ΩøÁî®„Åô„ÇãFreeCAD„Éâ„Ç≠„É•„É°„É≥„ÉàÂêç")
    p.add_argument(
        "--server-dir",
        default=r"C:\Users\USER\Documents\3dprinterrrr\mcp-server\freecad-mcp",
        help="freecad-mcp „ÅÆ„Éá„Ç£„É¨„ÇØ„Éà„É™",
    )
    p.add_argument("--only-text-feedback", action="store_true", help="MCP„Çí„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„É¢„Éº„Éâ„ÅßËµ∑Âãï")
    p.add_argument("--log-level", default="INFO", help="„É≠„Ç∞„É¨„Éô„É´ÔºàDEBUG/INFO/WARNING/ERRORÔºâ")
    p.add_argument("--show-tool-calls", action="store_true", help="„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„Å®ÁµêÊûú„ÇíË©≥Á¥∞Ë°®Á§∫")
    p.add_argument("--max-turns", type=int, default=30, help="1„ÇØ„Ç®„É™„ÅÇ„Åü„Çä„ÅÆÊúÄÂ§ß„Çø„Éº„É≥Êï∞")
    return p.parse_args()


ARGS = parse_args()
logging.basicConfig(level=getattr(logging, ARGS.log_level.upper(), logging.INFO))


SYSTEM_INSTRUCTIONS_TEMPLATE = """
„ÅÇ„Å™„Åü„ÅØFreeCAD MCP„ÉÑ„Éº„É´„Çí‰Ωø„ÅÜCAD„Ç™„Éö„É¨„Éº„Çø„Åß„Åô„ÄÇ
ÂøÖ„Åö„Éü„É™„É°„Éº„Éà„É´(mm)Âçò‰Ωç„ÅßÂØ∏Ê≥ï„ÇíÊòéÁ§∫„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
doc_name={DOC_NAME}„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®

„ÄêÈáçË¶Å„Äë„ÉÑ„Éº„É´ÁµêÊûú„ÅÆÊâ±„ÅÑ:
- „Åô„Åπ„Å¶„ÅÆ„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅØÊàêÂäü„Åó„Åæ„Åô
- get_object, get_objects „Å™„Å©„ÅÆÁµêÊûú„ÇíÊ≠£Á¢∫„Å´Ë™≠„ÅøÂèñ„Å£„Å¶„Åè„Å†„Åï„ÅÑ
- Â∫ßÊ®ô„ÄÅÂØ∏Ê≥ï„ÄÅ„Éó„É≠„Éë„ÉÜ„Ç£ÊÉÖÂ†±„ÇíÂÖ∑‰ΩìÁöÑ„Å´Â†±Âëä„Åó„Å¶„Åè„Å†„Åï„ÅÑ

ÂêÑ„Çø„Éº„É≥„ÅßË°å„ÅÜ„Åì„Å®:
1) ÂÆüË°åË®àÁîª(Á∞°ÊΩî)
2) ÂÆüË°å„Åô„ÇãMCP„ÉÑ„Éº„É´Âëº„Å≥Âá∫„ÅóÔºà‰ΩúÊàê/Á∑®ÈõÜ„ÅÆÂØæË±°Âêç„ÉªÂØ∏Ê≥ïÔºâ
3) „ÉÑ„Éº„É´ÁµêÊûú„ÅÆË©≥Á¥∞„Å™Â†±ÂëäÔºàÂ∫ßÊ®ô„ÄÅÂØ∏Ê≥ï„Å™„Å©ÂÖ∑‰ΩìÁöÑ„Å™Êï∞ÂÄ§Ôºâ
4) ÁîüÊàê/Â§âÊõ¥„Åó„Åü„Ç™„Éñ„Ç∏„Çß„ÇØ„ÉàÂêç„ÅÆ‰∏ÄË¶ß

Âá∫Âäõ„ÅØ„ÉÜ„Ç≠„Çπ„Éà‰∏≠ÂøÉ„ÄÇÁîªÂÉè„ÅØËøî„Åï„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ
""".strip()


def make_server() -> MCPServerStdio:
    """uvÂ≠òÂú®Á¢∫Ë™ç„ÅÆ„ÅÜ„Åà„Åß MCPServerStdio „ÇíÁîüÊàê"""
    if shutil.which("uv") is None:
        raise RuntimeError("uv „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ'pipx install uv' „Å™„Å©„ÅßÂ∞éÂÖ•„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

    uv_args = ["--directory", ARGS.server_dir, "run", "freecad-mcp"]
    if ARGS.only_text_feedback:
        uv_args.append("--only-text-feedback")

    return MCPServerStdio(
        name="FreeCAD via uv",
        params={"command": "uv", "args": uv_args},
        client_session_timeout_seconds=180,
    )


async def ensure_document(server: MCPServerStdio, doc_name: str) -> None:
    """FreeCAD„Éâ„Ç≠„É•„É°„É≥„Éà doc_name „ÇíÂøÖ„ÅöÊ∫ñÂÇô„Åô„Çã"""
    try:
        docs = await server.call_tool("get_documents", {})
        names = []
        if isinstance(docs, list):
            for d in docs:
                names.append(d.get("Name") or d.get("name"))

        if doc_name not in names:
            logging.info("Document '%s' not found. Creating...", doc_name)
            await server.call_tool("create_document", {"name": doc_name})

        await server.call_tool("set_active_document", {"doc_name": doc_name})

        # „Éì„É•„ÉºÂàùÊúüÂåñÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
        try:
            await server.call_tool("get_view", {"doc_name": doc_name})
            await server.call_tool(
                "set_view",
                {"doc_name": doc_name, "viewAxonometric": True, "fitAll": True},
            )
        except Exception as e:
            logging.debug("View init skipped: %s", e)

    except Exception as e:
        logging.error("ensure_document failed: %s", e)
        raise


def mcp_tool_to_openai_function(tool) -> Dict[str, Any]:
    """MCP„ÉÑ„Éº„É´„ÇíOpenAI„ÅÆfunctionÂΩ¢Âºè„Å´Â§âÊèõ"""
    return {
        "type": "function",
        "function": {
            "name": tool.name,
            "description": tool.description or f"MCP tool: {tool.name}",
            "parameters": tool.inputSchema if hasattr(tool, 'inputSchema') else {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    }


def format_tool_result(result) -> str:
    """„ÉÑ„Éº„É´ÁµêÊûú„ÇíË™≠„Åø„ÇÑ„Åô„Åè„Éï„Ç©„Éº„Éû„ÉÉ„Éà"""
    # CallToolResult „Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÅÆÂá¶ÁêÜ
    if hasattr(result, 'content'):
        text_parts = []
        for item in result.content:
            if hasattr(item, 'type'):
                if item.type == 'text':
                    text_parts.append(item.text)
                elif item.type == 'image':
                    text_parts.append('[ÁîªÂÉè„Éá„Éº„Çø]')
        return '\n'.join(text_parts) if text_parts else str(result)
    elif isinstance(result, dict):
        return json.dumps(result, ensure_ascii=False, indent=2)
    elif isinstance(result, list):
        return json.dumps(result, ensure_ascii=False, indent=2)
    else:
        return str(result)


def inject_doc_name(user_text: str, doc_name: str) -> str:
    """„É¢„Éá„É´„ÅÆÂèñ„Çä„Åì„Åº„ÅóÂØæÁ≠ñ„Å®„Åó„Å¶„ÄÅÂêÑ„Éó„É≠„É≥„Éó„ÉàÂÖàÈ†≠„Å´Èö†„ÅóÊåáÁ§∫„Çí‰ªò‰∏é"""
    prefix = f"(ÂøÖ„ÅöÂÖ®MCP„ÉÑ„Éº„É´ÂºïÊï∞„Å´ doc_name='{doc_name}' „ÇíÂê´„ÇÅ„ÄÅÂØ∏Ê≥ï„ÅØmm„ÅßÊòéÁ§∫„Åó„Å¶„Åè„Å†„Åï„ÅÑ)\n"
    return prefix + user_text


async def chat_with_tools(
    client: AsyncOpenAI,
    server: MCPServerStdio,
    messages: List[Dict[str, Any]],
    tools: List[Dict[str, Any]],
    model: str
) -> tuple[str, List[Dict[str, Any]]]:
    """
    OpenAI API„Çí‰Ωø„Å£„Å¶„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÇíÂê´„ÇÄ‰ºöË©±„ÇíÂÆüË°å
    
    Returns:
        (ÊúÄÁµÇÁöÑ„Å™„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„ÅÆÂøúÁ≠î, Êõ¥Êñ∞„Åï„Çå„Åü„É°„ÉÉ„Çª„Éº„Ç∏Â±•Ê≠¥)
    """
    current_messages = messages.copy()
    
    for turn in range(ARGS.max_turns):
        logging.debug(f"Turn {turn + 1}/{ARGS.max_turns}")
        
        # OpenAI API„ÇíÂëº„Å≥Âá∫„Åó
        response = await client.chat.completions.create(
            model=model,
            messages=current_messages,
            tools=tools,
            tool_choice="auto"
        )
        
        assistant_message = response.choices[0].message
        
        # „Ç¢„Ç∑„Çπ„Çø„É≥„Éà„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂ±•Ê≠¥„Å´ËøΩÂä†
        current_messages.append({
            "role": "assistant",
            "content": assistant_message.content,
            "tool_calls": [tc.model_dump() for tc in assistant_message.tool_calls] if assistant_message.tool_calls else None
        })
        
        # „Ç¢„Ç∑„Çπ„Çø„É≥„Éà„ÅÆÂøúÁ≠î„ÇíË°®Á§∫
        if assistant_message.content:
            print(assistant_message.content, flush=True)
        
        # „ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„Åå„Å™„Åë„Çå„Å∞ÁµÇ‰∫Ü
        if not assistant_message.tool_calls:
            break
        
        # „ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÇíÂá¶ÁêÜ
        print("\n" + "="*60)
        print("üîß „ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó")
        print("="*60)
        
        for tool_call in assistant_message.tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)
            
            if ARGS.show_tool_calls:
                print(f"\nüìå {tool_name}")
                print(f"   ÂºïÊï∞: {json.dumps(tool_args, ensure_ascii=False)}")
            
            # MCP„Çµ„Éº„Éê„Éº„Åß„ÉÑ„Éº„É´„ÇíÂÆüË°å
            try:
                tool_result = await server.call_tool(tool_name, tool_args)
                
                # CallToolResult „ÇíÊñáÂ≠óÂàó„Å´Â§âÊèõ
                if hasattr(tool_result, 'content'):
                    # content „É™„Çπ„Éà„Åã„Çâ„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„ÅøÊäΩÂá∫
                    text_parts = []
                    for item in tool_result.content:
                        if hasattr(item, 'type') and item.type == 'text':
                            text_parts.append(item.text)
                    tool_result_str = '\n'.join(text_parts) if text_parts else str(tool_result)
                else:
                    tool_result_str = json.dumps(tool_result, ensure_ascii=False) if isinstance(tool_result, (dict, list)) else str(tool_result)
                
                # ÁµêÊûú„ÇíË°®Á§∫
                print(f"\nüìä ÁµêÊûú:")
                formatted_result = format_tool_result(tool_result)
                if len(formatted_result) > 1000:
                    print(formatted_result[:1000])
                    print("... (ÁúÅÁï•)")
                else:
                    print(formatted_result)
                
                # „ÉÑ„Éº„É´ÁµêÊûú„Çí„É°„ÉÉ„Çª„Éº„Ç∏Â±•Ê≠¥„Å´ËøΩÂä†ÔºàÊñáÂ≠óÂàó„Å®„Åó„Å¶Ôºâ
                current_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result_str
                })
                
            except Exception as e:
                error_msg = f"„ÉÑ„Éº„É´ÂÆüË°å„Ç®„É©„Éº: {str(e)}"
                logging.error(error_msg)
                print(f"\n‚ùå {error_msg}")
                
                # „Ç®„É©„Éº„ÇÇ„É°„ÉÉ„Çª„Éº„Ç∏Â±•Ê≠¥„Å´ËøΩÂä†ÔºàÊñáÂ≠óÂàó„Å®„Åó„Å¶Ôºâ
                current_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": f'{{"error": "{str(e)}"}}'
                })
        
        print("="*60 + "\n")
        
        # Ê¨°„ÅÆ„Çø„Éº„É≥„Å∏Ôºà„ÉÑ„Éº„É´ÁµêÊûú„ÇíÂèó„Åë„Å¶AI„ÅåÂøúÁ≠îÔºâ
    
    else:
        # ÊúÄÂ§ß„Çø„Éº„É≥Êï∞„Å´ÈÅî„Åó„Åü
        logging.warning(f"ÊúÄÂ§ß„Çø„Éº„É≥Êï∞ {ARGS.max_turns} „Å´ÈÅî„Åó„Åæ„Åó„Åü")
    
    # ÊúÄÁµÇÁöÑ„Å™„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„ÅÆÂøúÁ≠î„ÇíÂèñÂæó
    final_response = current_messages[-1]["content"] if current_messages[-1]["role"] == "assistant" else ""
    
    return final_response, current_messages


async def main():
    # OpenAI„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÅÆÊ∫ñÂÇô
    openai_client = AsyncOpenAI()
    server: Optional[MCPServerStdio] = None

    try:
        # MCP„Çµ„Éº„ÉêÊé•Á∂ö
        server = make_server()
        print("[Ëµ∑Âãï] MCP„Çµ„Éº„Éê„Å∏Êé•Á∂ö‰∏≠‚Ä¶")
        await server.connect()

        # „ÉÑ„Éº„É´„É™„Çπ„Éà„ÇíÂèñÂæó„Åó„Å¶OpenAIÂΩ¢Âºè„Å´Â§âÊèõ
        mcp_tools = await server.list_tools()
        openai_tools = [mcp_tool_to_openai_function(tool) for tool in mcp_tools]
        
        logging.info("[MCP„ÉÑ„Éº„É´] %s", [t.name for t in mcp_tools])
        logging.info("[OpenAIÂΩ¢Âºè„Å´Â§âÊèõ] %d tools", len(openai_tools))
        logging.info("[„É¢„Éá„É´] %s", ARGS.model)
        logging.info("[„Éâ„Ç≠„É•„É°„É≥„Éà] %s", ARGS.doc_name)

        # „Éâ„Ç≠„É•„É°„É≥„ÉàÊ∫ñÂÇôÔºàÂ≠òÂú®‰øùË®ºÔºâ
        await ensure_document(server, ARGS.doc_name)

        # „Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„Éà
        system_instructions = SYSTEM_INSTRUCTIONS_TEMPLATE.format(DOC_NAME=ARGS.doc_name)

        # „É°„ÉÉ„Çª„Éº„Ç∏Â±•Ê≠¥
        messages = [
            {"role": "system", "content": system_instructions}
        ]

        # „Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„Éó
        print("==== FreeCAD ÂØæË©±„É¢„Éº„Éâ (OpenAIÁõ¥Êé•Âëº„Å≥Âá∫„ÅóÁâà) ====")
        print("‰æã: „ÄéÂçäÂæÑ30mm„ÅÆÁêÉ„Çí‰ΩúÊàê„Äè„ÄéSphere_001„ÇíÂçäÂæÑ40mm„Å´Â§âÊõ¥„Äè„Å™„Å©")
        print("Â∫ßÊ®ô„ÇíÂèñÂæó: „ÄéSphere_001„ÅÆÂ∫ßÊ®ô„ÇíÊïô„Åà„Å¶„Äè")
        print("ÁµÇ‰∫Ü: /exit")
        print()

        # ÊúÄÂàù„ÅÆ‰∏ÄË®Ä
        print("ü§ñ ÂàùÊúüÂåñ‰∏≠...\n")
        messages.append({
            "role": "user",
            "content": inject_doc_name("FreeCAD„Åß‰∫∫Â∑•Ë°õÊòü„Çí‰Ωú„Å£„Å¶„Åè„Å†„Åï„ÅÑ", ARGS.doc_name)
        })
        
        _, messages = await chat_with_tools(
            openai_client,
            server,
            messages,
            openai_tools,
            ARGS.model
        )

        # REPL
        while True:
            try:
                user_text = input("\n> ").strip()
            except (EOFError, KeyboardInterrupt):
                print("\n[ÁµÇ‰∫ÜË¶ÅÊ±Ç]")
                break

            if not user_text:
                continue
            if user_text.lower() in ("/exit", "exit", "quit", "/q"):
                break

            # „É¶„Éº„Ç∂„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
            messages.append({
                "role": "user",
                "content": inject_doc_name(user_text, ARGS.doc_name)
            })

            # ‰ºöË©±ÂÆüË°å
            _, messages = await chat_with_tools(
                openai_client,
                server,
                messages,
                openai_tools,
                ARGS.model
            )

    except asyncio.CancelledError:
        logging.warning("cancelled")
        raise
    except Exception as e:
        logging.exception("fatal error: %s", e)
    finally:
        # „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
        if server:
            try:
                await server.cleanup()
            except Exception:
                pass
        try:
            await openai_client.close()
        except Exception:
            pass


if __name__ == "__main__":
    asyncio.run(main())
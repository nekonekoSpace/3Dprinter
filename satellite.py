#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import asyncio
import json
import logging
import shutil
import base64
from typing import Optional, List, Dict, Any

from dotenv import load_dotenv
from openai import AsyncOpenAI
from agents.mcp import MCPServerStdio

load_dotenv()

import argparse
from PIL import Image
import numpy as np
import sys

# Windowsã®æ—§ç’°å¢ƒå¯¾ç­–ï¼ˆå…¥ã£ã¦ã„ã‚Œã°è‡ªå‹•ã§æœ‰åŠ¹åŒ–ï¼‰
try:
    import colorama
    colorama.just_fix_windows_console()
except Exception:
    pass

ASCII_CHARS = "@%#*+=-:. "  # æš—â†’æ˜ï¼ˆå¥½ã¿ã§å¤‰æ›´å¯ï¼‰

def print_color_ascii(image_path, width=200, line_scale=0.55, charset=ASCII_CHARS):
    img = Image.open(image_path).convert("RGB")
    aspect = img.height / img.width
    h = max(1, int(width * aspect * line_scale))     # æ–‡å­—ã®ç¸¦æ¨ªæ¯”è£œæ­£
    img = img.resize((width, h), Image.Resampling.BICUBIC)

    arr = np.array(img)                              # (H, W, 3)
    # è¼åº¦ã§ä½¿ç”¨æ–‡å­—ã‚’é¸ã¶
    lum = (0.299*arr[...,0] + 0.587*arr[...,1] + 0.114*arr[...,2]).astype("uint8")
    idx = (lum * ((len(charset)-1)/255)).astype(int)

    reset = "\x1b[0m"
    out = []
    for y in range(arr.shape[0]):
        row = []
        for x in range(arr.shape[1]):
            r, g, b = map(int, arr[y, x])
            ch = charset[idx[y, x]]
            row.append(f"\x1b[38;2;{r};{g};{b}m{ch}")  # 24bitå‰æ™¯è‰²
        out.append("".join(row) + reset)
    print("\n".join(out))


width = 100
image = "./b.png"    
line_scale = 0.55

    
print_color_ascii(image, width, line_scale)

def parse_args():
    p = argparse.ArgumentParser(description="FreeCAD MCP + OpenAI ç›´æ¥å‘¼ã³å‡ºã—REPL")
    # p.add_argument("--model", default="gpt-4o", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, gpt-4o-miniï¼‰")
    # p.add_argument("--model", default="gpt-o3", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, gpt-4o-miniï¼‰")
    # p.add_argument("--model", default="gpt-4o-mini", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, gpt-4o-miniï¼‰")
    p.add_argument("--model", default="gpt-4.1", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, gpt-4o-miniï¼‰")
    # p.add_argument("--model", default="gpt-5-mini", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, gpt-4o-miniï¼‰")
    # p.add_argument("--model", default="gpt-5", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, gpt-4o-miniï¼‰")
    p.add_argument("--doc-name", default="Main", help="ä½œæ¥­ã«ä½¿ç”¨ã™ã‚‹FreeCADãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå")
    p.add_argument(
        "--server-dir",
        default=r"C:\Users\USER\Documents\3dprinterrrr\mcp-server\freecad-mcp",
        help="freecad-mcp ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
    )
    p.add_argument("--only-text-feedback", action="store_true", help="MCPã‚’ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•")
    p.add_argument("--log-level", default="INFO", help="ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ï¼ˆDEBUG/INFO/WARNING/ERRORï¼‰")
    p.add_argument("--show-tool-calls", action="store_true", help="ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¨çµæœã‚’è©³ç´°è¡¨ç¤º")
    p.add_argument("--max-turns", type=int, default=30, help="1ã‚¯ã‚¨ãƒªã‚ãŸã‚Šã®æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°")
    return p.parse_args()


ARGS = parse_args()
logging.basicConfig(level=getattr(logging, ARGS.log_level.upper(), logging.INFO))


SYSTEM_INSTRUCTIONS_TEMPLATE = """
ã‚ãªãŸã¯FreeCAD MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†CADã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã§ã™ã€‚
å¿…ãšãƒŸãƒªãƒ¡ãƒ¼ãƒˆãƒ«(mm)å˜ä½ã§å¯¸æ³•ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚

ã€3Dãƒ—ãƒªãƒ³ã‚¿ãƒ¼ã§å°åˆ·ã™ã‚‹ãŸã‚ã«å¿…ãšæ¬¡ã®ã“ã¨ã‚’å®ˆã£ã¦ãã ã•ã„ã€‚ã€‘
ãƒ»3ãx3ãx3ãã«æ¨¡å‹ãŒåã¾ã‚‹ã“ã¨
ãƒ»å¿…ãšå¹…ã‚„åšã•ãŒ5ãœä»¥ä¸Šã‚ã‚‹ã“ã¨
ãƒ»ã™ã¹ã¦ã®ãƒ‘ãƒ¼ãƒ„ãŒãã£ã¤ã„ã¦ã„ã‚‹ã“ã¨
ãƒ»zè»¸æ­£æ–¹å‘ãŒä¸Šã‚’è¡¨ã—ã¾ã™
doc_name={DOC_NAME}ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨

ã€é‡è¦ã€‘ãƒ„ãƒ¼ãƒ«çµæœã®æ‰±ã„:
- ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¯æˆåŠŸã—ã¾ã™
- get_object, get_objects ãªã©ã®çµæœã‚’æ­£ç¢ºã«èª­ã¿å–ã£ã¦ãã ã•ã„
- åº§æ¨™ã€å¯¸æ³•ã€ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æƒ…å ±ã‚’å…·ä½“çš„ã«å ±å‘Šã—ã¦ãã ã•ã„
- [ç”»åƒç”Ÿæˆæ¸ˆã¿]ã¨ã„ã†ãƒãƒ¼ã‚«ãƒ¼ãŒã‚ã‚‹å ´åˆã€è¦–è¦šçš„ãªç¢ºèªãŒè¡Œã‚ã‚ŒãŸã“ã¨ã‚’æ„å‘³ã—ã¾ã™

å„ã‚¿ãƒ¼ãƒ³ã§è¡Œã†ã“ã¨:
1) å®Ÿè¡Œè¨ˆç”»(ç°¡æ½”)
2) å®Ÿè¡Œã™ã‚‹MCPãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼ˆä½œæˆ/ç·¨é›†ã®å¯¾è±¡åãƒ»å¯¸æ³•ï¼‰
3) ãƒ„ãƒ¼ãƒ«çµæœã®è©³ç´°ãªå ±å‘Šï¼ˆåº§æ¨™ã€å¯¸æ³•ãªã©å…·ä½“çš„ãªæ•°å€¤ï¼‰
4) ç”Ÿæˆ/å¤‰æ›´ã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåã®ä¸€è¦§

å‰ã®ä¼šè©±ã§ä½œæˆã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¦šãˆã¦ãŠã‚Šã€ãã‚Œã‚‰ã‚’å‚ç…§ãƒ»ç·¨é›†ã§ãã¾ã™ã€‚
""".strip()


class ImageStore:
    """ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self):
        self.images = {}
        self.counter = 0
    
    def add(self, image_data: str) -> str:
        """ç”»åƒã‚’ä¿å­˜ã—ã¦IDã‚’è¿”ã™"""
        self.counter += 1
        img_id = f"img_{self.counter}"
        self.images[img_id] = image_data
        return img_id
    
    def get(self, img_id: str) -> Optional[str]:
        """IDã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        return self.images.get(img_id)
    
    def clear(self):
        """å…¨ç”»åƒã‚’ã‚¯ãƒªã‚¢"""
        self.images.clear()
        self.counter = 0


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ç”»åƒã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
image_store = ImageStore()


def make_server() -> MCPServerStdio:
    """uvå­˜åœ¨ç¢ºèªã®ã†ãˆã§ MCPServerStdio ã‚’ç”Ÿæˆ"""
    if shutil.which("uv") is None:
        raise RuntimeError("uv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'pipx install uv' ãªã©ã§å°å…¥ã—ã¦ãã ã•ã„ã€‚")

    uv_args = ["--directory", ARGS.server_dir, "run", "freecad-mcp"]
    if ARGS.only_text_feedback:
        uv_args.append("--only-text-feedback")

    return MCPServerStdio(
        name="FreeCAD via uv",
        params={"command": "uv", "args": uv_args},
        client_session_timeout_seconds=60,
    )


async def ensure_document(server: MCPServerStdio, doc_name: str) -> None:
    """FreeCADãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ doc_name ã‚’å¿…ãšæº–å‚™ã™ã‚‹"""
    try:
        docs = await server.call_tool("get_documents", {})
        names = []
        if isinstance(docs, list):
            for d in docs:
                names.append(d.get("Name") or d.get("name"))

        if doc_name not in names:
            logging.info("Document '%s' not found. Creating...", doc_name)
            await server.call_tool("create_document", {"name": doc_name})

        await server.call_tool("set_active_document", {"doc_name": doc_name})

        # ãƒ“ãƒ¥ãƒ¼åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        try:
            await server.call_tool("get_view", {"doc_name": doc_name})
            await server.call_tool(
                "set_view",
                {"doc_name": doc_name, "viewAxonometric": True, "fitAll": True},
            )
        except Exception as e:
            logging.debug("View init skipped: %s", e)

    except Exception as e:
        logging.error("ensure_document failed: %s", e)
        raise


def mcp_tool_to_openai_function(tool) -> Dict[str, Any]:
    """MCPãƒ„ãƒ¼ãƒ«ã‚’OpenAIã®functionå½¢å¼ã«å¤‰æ›"""
    return {
        "type": "function",
        "function": {
            "name": tool.name,
            "description": tool.description or f"MCP tool: {tool.name}",
            "parameters": tool.inputSchema if hasattr(tool, 'inputSchema') else {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    }


def extract_content_from_tool_result(result) -> tuple[str, Optional[str]]:
    """
    ãƒ„ãƒ¼ãƒ«çµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’æŠ½å‡º
    Returns: (text_content, base64_image_data)
    """
    text_parts = []
    image_data = None
    
    if hasattr(result, 'content'):
        for item in result.content:
            if hasattr(item, 'type'):
                if item.type == 'text':
                    text_parts.append(item.text)
                elif item.type == 'image' and hasattr(item, 'data'):
                    # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                    image_data = item.data
    
    text_content = '\n'.join(text_parts) if text_parts else json.dumps(result, ensure_ascii=False) if isinstance(result, (dict, list)) else str(result)
    
    return text_content, image_data


def format_tool_result_for_display(result) -> str:
    """ãƒ„ãƒ¼ãƒ«çµæœã‚’è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    text, has_image = extract_content_from_tool_result(result)
    if has_image:
        return text + "\n[ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚ã‚Š]"
    return text


async def chat_with_tools(
    client: AsyncOpenAI,
    server: MCPServerStdio,
    messages: List[Dict[str, Any]],
    tools: List[Dict[str, Any]],
    model: str
) -> tuple[str, List[Dict[str, Any]]]:
    """
    OpenAI APIã‚’ä½¿ã£ã¦ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å«ã‚€ä¼šè©±ã‚’å®Ÿè¡Œ
    
    Returns:
        (æœ€çµ‚çš„ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”, æ›´æ–°ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´)
    """
    current_messages = messages.copy()
    
    for turn in range(ARGS.max_turns):
        logging.debug(f"Turn {turn + 1}/{ARGS.max_turns}")
        
        # OpenAI APIã‚’å‘¼ã³å‡ºã—
        response = await client.chat.completions.create(
            model=model,
            messages=current_messages,
            tools=tools,
            tool_choice="auto"
        )
        
        assistant_message = response.choices[0].message
        
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
        assistant_dict = {
            "role": "assistant",
            "content": assistant_message.content,
        }
        if assistant_message.tool_calls:
            assistant_dict["tool_calls"] = [tc.model_dump() for tc in assistant_message.tool_calls]
        
        current_messages.append(assistant_dict)
        
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’è¡¨ç¤º
        if assistant_message.content:
            print(f"\n {assistant_message.content}", flush=True)
        
        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒãªã‘ã‚Œã°çµ‚äº†
        if not assistant_message.tool_calls:
            break
        
        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å‡¦ç†
        print("\n" + "="*60)
        print(" ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—")
        print("="*60)
        
        for tool_call in assistant_message.tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)
            
            if ARGS.show_tool_calls:
                print(f"\n {tool_name}")
                print(f"   å¼•æ•°: {json.dumps(tool_args, ensure_ascii=False)}")
            else:
                print(f"\n {tool_name} å®Ÿè¡Œä¸­...")
            
            # MCPã‚µãƒ¼ãƒãƒ¼ã§ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
            try:
                tool_result = await server.call_tool(tool_name, tool_args)
                
                # ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’æŠ½å‡º
                text_content, image_data = extract_content_from_tool_result(tool_result)
                
                # ç”»åƒãŒã‚ã‚‹å ´åˆã¯ä¿å­˜ã—ã¦ãƒãƒ¼ã‚«ãƒ¼ã‚’è¿½åŠ 
                if image_data:
                    img_id = image_store.add(image_data)
                    text_content += f"\n[ç”»åƒç”Ÿæˆæ¸ˆã¿: {img_id}]"
                    logging.debug(f"ç”»åƒã‚’ä¿å­˜: {img_id}")
                
                # çµæœã‚’è¡¨ç¤º
                print(f" çµæœ:")
                display_text = format_tool_result_for_display(tool_result)
                if len(display_text) > 500:
                    print(display_text[:500])
                    print("... (çœç•¥)")
                else:
                    print(display_text)
                
                # ãƒ„ãƒ¼ãƒ«çµæœã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
                current_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": text_content
                })
                
            except Exception as e:
                error_msg = f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
                logging.error(error_msg)
                print(f"âŒ {error_msg}")
                
                # ã‚¨ãƒ©ãƒ¼ã‚‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
                current_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": f'{{"error": "{str(e)}"}}'
                })
        
        print("="*60)
        
        # æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã¸ï¼ˆãƒ„ãƒ¼ãƒ«çµæœã‚’å—ã‘ã¦AIãŒå¿œç­”ï¼‰
    
    else:
        # æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ãŸ
        logging.warning(f"æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•° {ARGS.max_turns} ã«é”ã—ã¾ã—ãŸ")
    
    # æœ€çµ‚çš„ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å–å¾—
    final_response = ""
    for msg in reversed(current_messages):
        if msg["role"] == "assistant" and msg.get("content"):
            final_response = msg["content"]
            break
    
    return final_response, current_messages


async def main():
    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æº–å‚™
    openai_client = AsyncOpenAI()
    server: Optional[MCPServerStdio] = None

    try:
        # MCPã‚µãƒ¼ãƒæ¥ç¶š
        server = make_server()
        print("[èµ·å‹•] MCPã‚µãƒ¼ãƒã¸æ¥ç¶šä¸­â€¦")
        await server.connect()

        # ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦OpenAIå½¢å¼ã«å¤‰æ›
        mcp_tools = await server.list_tools()
        openai_tools = [mcp_tool_to_openai_function(tool) for tool in mcp_tools]
        
        logging.info("[MCPãƒ„ãƒ¼ãƒ«] %s", [t.name for t in mcp_tools])
        logging.info("[OpenAIå½¢å¼ã«å¤‰æ›] %d tools", len(openai_tools))
        logging.info("[ãƒ¢ãƒ‡ãƒ«] %s", ARGS.model)
        logging.info("[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ] %s", ARGS.doc_name)

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæº–å‚™ï¼ˆå­˜åœ¨ä¿è¨¼ï¼‰
        await ensure_document(server, ARGS.doc_name)

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_instructions = SYSTEM_INSTRUCTIONS_TEMPLATE.format(DOC_NAME=ARGS.doc_name)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ï¼ˆä¼šè©±å…¨ä½“ã‚’é€šã—ã¦ä¿æŒï¼‰
        messages = [
            {"role": "system", "content": system_instructions}
        ]

        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        print("==== FreeCAD å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ (OpenAIç›´æ¥å‘¼ã³å‡ºã—ç‰ˆ) ====")
        print("ä¾‹: ã€åŠå¾„30mmã®çƒã‚’ä½œæˆã€ã€Sphere_001ã‚’åŠå¾„40mmã«å¤‰æ›´ã€ãªã©")
        print("åº§æ¨™ã‚’å–å¾—: ã€Sphere_001ã®åº§æ¨™ã‚’æ•™ãˆã¦ã€")
        print("å±¥æ­´ãƒªã‚»ãƒƒãƒˆ: /reset")
        print("å±¥æ­´ç¢ºèª: /history")
        print("çµ‚äº†: /exit")
        print()

        # æœ€åˆã®ä¸€è¨€
        print(" åˆæœŸåŒ–ä¸­...\n")
        first_message = "(å¿…ãšå…¨MCPãƒ„ãƒ¼ãƒ«å¼•æ•°ã« doc_name='Main' ã‚’å«ã‚ã€å¯¸æ³•ã¯mmã§æ˜ç¤ºã—ã¦ãã ã•ã„)\nFreeCADã§äººå·¥è¡›æ˜Ÿã‚’ä½œã£ã¦ãã ã•ã„ã€‚å¿…ãšã©ã‚“ãªã‚‚ã®ãŒã©ã“ã«é…ç½®ã•ã‚Œã‚‹ã‹è€ƒãˆã¦ã‹ã‚‰ä½œæ¥­ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚"
        messages.append({
            "role": "user",
            "content": first_message
        })
        
        _, messages = await chat_with_tools(
            openai_client,
            server,
            messages,
            openai_tools,
            ARGS.model
        )

        # REPL
        while True:
            try:
                user_text = input("\nğŸ’¬ > ").strip()
            except (EOFError, KeyboardInterrupt):
                print("\n[çµ‚äº†è¦æ±‚]")
                break

            if not user_text:
                continue
            if user_text.lower() in ("/exit", "exit", "quit", "/q"):
                break
            if user_text.lower() == "/reset":
                print("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                messages = [
                    {"role": "system", "content": system_instructions}
                ]
                image_store.clear()
                continue
            if user_text.lower() == "/history":
                print(f" ç¾åœ¨ã®ä¼šè©±å±¥æ­´: {len(messages)} ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
                print(f" ä¿å­˜ã•ã‚ŒãŸç”»åƒ: {image_store.counter} æš")
                for i, msg in enumerate(messages[-10:]):  # æœ€å¾Œã®10ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                    role = msg.get("role", "unknown")
                    content = msg.get("content", "")
                    if isinstance(content, str):
                        if len(content) > 100:
                            content = content[:100] + "..."
                    else:
                        content = "[è¤‡åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„]"
                    print(f"  [{i}] {role}: {content}")
                continue

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            messages.append({
                "role": "user",
                "content": user_text
            })

            # ä¼šè©±å®Ÿè¡Œï¼ˆmessagesã¯æ›´æ–°ã•ã‚Œã‚‹ï¼‰
            _, messages = await chat_with_tools(
                openai_client,
                server,
                messages,
                openai_tools,
                ARGS.model
            )

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            logging.debug(f"ä¼šè©±å±¥æ­´é•·: {len(messages)} ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")

    except asyncio.CancelledError:
        logging.warning("cancelled")
        raise
    except Exception as e:
        logging.exception("fatal error: %s", e)
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if server:
            try:
                await server.cleanup()
            except Exception:
                pass
        try:
            await openai_client.close()
        except Exception:
            pass


if __name__ == "__main__":
    asyncio.run(main())